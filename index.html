<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="files/jemdoc.css" type="text/css" />

<title>Kai Zhang</title>

</head>
<body>

<!-- Project
<div class="menu"> <a href="#home">Home</a> 
<a href="#publications">Publications</a> 
<a href="#services">Services</a> 
<a href="#awards">Awards</a>  
</div>
 -->
 
<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 
<!--
<div id="toptitle">
<h1>Kai Zhang</h1>
</div>
 -->


<table class="imgtable"><tr><td>
<a href="./"><img src="./files/photo3.jpg" alt="" height="200px" /></a>&nbsp;</td>
<td align="left"><p><font size="4">Kai Zhang (张 凯)</font><br />
<br />
<a href="https://vision.ee.ethz.ch/the-institute.html">Computer Vision Lab</a><br />
 Department of Information Technology and Electrical Engineering, <a href="https://ethz.ch/en.html" target="_blank">ETH Zurich</a><br />
<br />
ETF D117,
Sternwartstrasse 7, ETH Zentrum 8092, Zurich, Switzerland<br />

<br />
Email: cskaizhang@gmail.com <br />
[<a class="p1" href="https://scholar.google.com.hk/citations?user=0RycFIIAAAAJ&hl" target="_blank">Google Scholar</a>] [<a class="p2" href="https://github.com/cszn" target="_blank">Github</a>]
[<a href="https://www.researchgate.net/profile/Kai_Zhang210" target="_blank">ResearchGate</a>]</p>
</td></tr></table>

<h2>Biography</h2>
<p> I am currently a postdoctoral researcher at Computer Vision Lab, ETH Zurich, Switzerland, working with 
          Prof. <a href="https://ee.ethz.ch/the-department/faculty/professors/person-detail.OTAyMzM=.TGlzdC80MTEsMTA1ODA0MjU5.html" target="_blank">Luc Van Gool</a>
          and Dr. <a href="http://people.ee.ethz.ch/~timofter/" target="_blank">Radu Timofte</a>.  
          Before that, I received my Ph.D. degree from School of Computer Science and Technology, Harbin Institute of Technology, China, in 2019, 
		  under the supervision of Prof. <a href="http://www4.comp.polyu.edu.hk/~cslzhang/" target="_blank">Lei Zhang</a> 
          and Prof. <a href="http://homepage.hit.edu.cn/wangmengzuo" target="_blank">Wangmeng Zuo</a>.
          I was a research assistant from July, 2015 to July, 2017 and from July, 2018 to April, 2019 in Department of Computing of The Hong Kong Polytechnic University.
  </p>


<h2>Research Interest</h2>
I work in the field of image processing, specializing in particular on developing deep learning techniques for inverse problems in low-level computer vision.
I mainly investigate how to incorporate traditional model-based method and deep learning-based method for flexible, effective, efficient and interpretable image restoration. 
Recently, I focus on the following research topics:
<ul>
<li>Deep plug-and-play image restoration</li>
<li>Deep unfolding image restoration</li>
<li>Camera pipeline</li>
</ul>

<h2>PyTorch Toolbox for Image Restoration</h2>
<ul>
<li> <a href="https://github.com/cszn/KAIR" target="_blank">KAIR</a> (support training and testing for DnCNN, FFDNet, SRMD, USRNet, ESRGAN) </li>
</ul>


<h2>News</h2>
<ul>
<li>I plan to release the code of <a href="https://github.com/cszn/USRNet" target="_blank">USRNet</a> in May, 2020.</li>
<li>I am co-organizing the ECCV 2020 Workshop on <a href="https://data.vision.ee.ethz.ch/cvl/aim20/" target="_blank">Advances in Image Manipulation</a></li>
<li>Two papers accepted in CVPR 2020.</li>
<li>I am co-organizing the CVPR 2020 Workshop on <a href="https://data.vision.ee.ethz.ch/cvl/ntire20/" target="_blank">New Trends in Image Restoration and Enhancement</a></li>
</ul>

<!-- Project -->
<a id="publications" class="anchor"></a>
<h2>Selected Publications</h2>

<table class="imgtable">
<!-- USRNet-->
<tr>
<td><img class="proj_thumb" src="https://github.com/cszn/USRNet/raw/master/figs/architecture.png" alt="" height="50px"/>&nbsp;</td>
<td>
<p class="pub_title">Deep Unfolding Network for Image Super-Resolution </p>
<p class="pub_author"><b>Kai Zhang</b>, Luc Van Gool, Radu Timofte<br>
IEEE International Conference on Computer Vision and Pattern Recognition</i>(<b>CVPR</b>), 2020.<br>
[<a href= "https://arxiv.org/pdf/2003.10428.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/cszn/USRNet" target="_blank">PyTorch Code</a>] 
[<a href="https://scholar.googleusercontent.com/citations?view_op=export_citations&user=0RycFIIAAAAJ&s=0RycFIIAAAAJ:qPeb-qHga9sC&citsig=AMD79ooAAAAAXqB50-qtmMP4iRH1Y7RnSUD_dZhyu-68&hl=zh-CN&cit_fmt=0" target="_blank">BibTex</a>]
</p> </td>
</tr>

<!-- deblur-->
<tr>
<td><img class="proj_thumb" src="https://github.com/csdwren/SelfDeblur/raw/master/results/demo/lai.jpg" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Neural Blind Deconvolution Using Deep Priors </p>
<p class="pub_author">Dongwei Ren, <b>Kai Zhang</b>, Qilong Wang, Qinghua Hu, Wangmeng Zuo<br>
IEEE International Conference on Computer Vision and Pattern Recognition</i>(<b>CVPR</b>), 2020.<br>
[<a href= "https://arxiv.org/pdf/1908.02197.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/csdwren/SelfDeblur" target="_blank">PyTorch Code</a>] 
[<a href="https://scholar.googleusercontent.com/citations?view_op=export_citations&user=0RycFIIAAAAJ&s=0RycFIIAAAAJ:wuD5JclIwkYC&citsig=AMD79ooAAAAAXqB5_0CEDCRiY68pKJknPQI1_ltPqi_H&hl=zh-CN&cit_fmt=0" target="_blank">BibTex</a>]
</p> </td>
</tr>


<!-- challenge-->
<tr>
<td><img class="proj_thumb" src="https://github.com/cszn/KAIR/raw/master/figs/imdn_block.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">AIM 2019 Challenge on Constrained Super-Resolution: Methods and Results</p>
<p class="pub_author"><b>Kai Zhang</b>, Shuhang Gu, Radu Timofte, and others<br>
IEEE International Conference on Computer Vision Workshops (<b>ICCVW</b>), 2019.<br>
[<a href= "https://arxiv.org/pdf/1911.01249.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/cszn/KAIR" target="_blank">PyTorch Code of Winner</a>] 
[<a href="https://scholar.googleusercontent.com/citations?view_op=export_citations&user=0RycFIIAAAAJ&s=0RycFIIAAAAJ:3MwzVuqRcA0C&citsig=AMD79ooAAAAAXqB6P2k6UjFgSMunjUxVdaoDwEkWFyak&hl=zh-CN&cit_fmt=0" target="_blank">BibTex</a>]
</p> </td>
</tr>


<!-- DPSR-->
<tr>
<td><img class="proj_thumb" src="https://github.com/cszn/DPSR/raw/master/testsets/BSD68/x4_m_dpsrgan/test_14_m_14.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Deep Plug-and-Play Super-Resolution for Arbitrary Blur Kernels</p>
<p class="pub_author"><b>Kai Zhang</b>, Wangmeng Zuo, Lei Zhang<br>
IEEE International Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2019.<br>
[<a href= "http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Deep_Plug-And-Play_Super-Resolution_for_Arbitrary_Blur_Kernels_CVPR_2019_paper.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/cszn/DPSR" target="_blank">PyTorch Code</a>] 
[<a href="https://scholar.googleusercontent.com/citations?view_op=export_citations&user=0RycFIIAAAAJ&s=0RycFIIAAAAJ:7VEv-pLvLSsC&citsig=AMD79ooAAAAAXqB6Zc-fPNxG-dwQT89smztwDqSgys7E&hl=zh-CN&cit_fmt=0" target="_blank">BibTex</a>]
</p> </td>
</tr>


<!-- SRMD-->
<tr>
<td><img class="proj_thumb" src="https://github.com/cszn/SRMD/raw/master/figs/architecture.png" alt="" height="55px"/>&nbsp;</td>
<td>
<p class="pub_title">Learning a Single Convolutional Super-Resolution Network for Multiple Degradations</p>
<p class="pub_author"><b>Kai Zhang</b>, Wangmeng Zuo, Lei Zhang<br>
IEEE International Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2018. <br>
[<a href= "http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/1440.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/cszn/SRMD" target="_blank">Matlab Code</a>] 
[<a href="https://github.com/cszn/KAIR" target="_blank">PyTorch Code</a>] 
[<a href="https://scholar.googleusercontent.com/citations?view_op=export_citations&user=0RycFIIAAAAJ&s=0RycFIIAAAAJ:RfUwGJFMQ-0C&citsig=AMD79ooAAAAAXqB6gSisiMczo21LIammtL4BfHzEvarh&hl=zh-CN&cit_fmt=0" target="_blank">BibTex</a>]
[Citations: <b>150</b>+]</p> </td>
</tr>


<!-- IRCNN-->
<tr>
<td><img class="proj_thumb" src="https://www.mathworks.com/matlabcentral/mlc-downloads/downloads/submissions/62439/versions/6/screenshot.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Learning Deep CNN Denoiser Prior for Image Restoration</p>
<p class="pub_author"><b>Kai Zhang</b>, Wangmeng Zuo, Shuhang Gu, Lei Zhang<br>
IEEE International Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2017. <br>
[<a href= "http://www4.comp.polyu.edu.hk/~cslzhang/paper/IRCNN_CVPR17.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/cszn/IRCNN" target="_blank">Matlab Code</a>] 
[<a href="https://scholar.googleusercontent.com/citations?view_op=export_citations&user=0RycFIIAAAAJ&s=0RycFIIAAAAJ:W2uZP3ddy8sC&citsig=AMD79ooAAAAAXqB6pH4ELz6rcYc0CI3lmbwi3OGkBb-0&hl=zh-CN&cit_fmt=0" target="_blank">BibTex</a>]
[Citations: <b>500</b>+]</p> </td>
</tr>

<!-- FFDNet-->
<tr>
<td><img class="proj_thumb" src="https://github.com/cszn/FFDNet/raw/master/utilities/figs/Frog.gif" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">FFDNet: Toward a Fast and Flexible Solution for CNN-based Image Denoising</p>
<p class="pub_author"><b>Kai Zhang</b>, Wangmeng Zuo, Lei Zhang<br>
IEEE Transactions on Image Processing (<b>TIP</b>), 27(9): 4608-4622, 2018.<br>
[<a href= "http://www4.comp.polyu.edu.hk/~cslzhang/paper/IRCNN_CVPR17.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/cszn/FFDNet" target="_blank">Matlab Code</a>] 
[<a href="https://github.com/cszn/KAIR" target="_blank">PyTorch Code</a>] 
[<a href="https://scholar.googleusercontent.com/citations?view_op=export_citations&user=0RycFIIAAAAJ&s=0RycFIIAAAAJ:cNe27ouKFcQC&citsig=AMD79ooAAAAAXqB6w3dJTSC7Lx9kObToJqmRbMYwrF4F&hl=zh-CN&cit_fmt=0" target="_blank">BibTex</a>]
[Citations: <b>290</b>+]</p> </td>
</tr>


<!-- DnCNN-->
<tr>
<td><img class="proj_thumb" src="https://github.com/cszn/DnCNN/raw/master/figs/input.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising</p>
<p class="pub_author"><b>Kai Zhang</b>, Wangmeng Zuo, Yunjin Chen, Deyu Meng, Lei Zhang<br>
IEEE Transactions on Image Processing (<b>TIP</b>), 26(7): 3142-3155, 2017.<br>
[<a href= "https://ieeexplore.ieee.org/document/7839189" target="_blank">Paper</a>] 
[<a href="https://github.com/cszn/DnCNN" target="_blank">Matlab Code</a>] 
[<a href="https://github.com/cszn/KAIR" target="_blank">PyTorch Code</a>] 
[<a href="https://scholar.googleusercontent.com/citations?view_op=export_citations&user=0RycFIIAAAAJ&s=0RycFIIAAAAJ:q0uBw5dMOAkC&citsig=AMD79ooAAAAAXqB5Hh5rwZahjQvvU3HKQJJSYPzaGHS4&hl=zh-CN&cit_fmt=0" target="_blank">BibTex</a>] 
[Citations: <b>1700</b>+] </p> </td>
</tr>

<!-- Blind IQA-->
<tr>
<td><img class="proj_thumb" src="https://ece.uwaterloo.ca/~zduanmu/tip2018biqa/images/gmad1.jpg" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">End-to-End Blind Image Quality Assessment Using Deep Neural Networks</p>
<p class="pub_author">Kede Ma, Wentao Liu, <b>Kai Zhang</b>, Zhengfang Duanmu, Zhou Wang, Wangmeng Zuo<br>
IEEE Transactions on Image Processing (<b>TIP</b>), 27(3): 1202-1213, 2017.<br>
[<a href= "https://ieeexplore.ieee.org/abstract/document/8110690" target="_blank">Paper</a>] 
[<a href="https://ece.uwaterloo.ca/~zduanmu/tip2018biqa/" target="_blank">Project Page</a>] 
[<a href="https://scholar.googleusercontent.com/citations?view_op=export_citations&user=0RycFIIAAAAJ&s=0RycFIIAAAAJ:rFyVMFCKTwsC&citsig=AMD79ooAAAAAXqB67YtgTuUq3b3TXagt9KUEDJ6PfB_2&hl=zh-CN&cit_fmt=0" target="_blank">BibTex</a>]
[Citations: <b>90</b>+]</p> </td>
</tr>

<!-- CBDNet-->
<tr>
<td><img class="proj_thumb" src="https://github.com/GuoShi28/CBDNet/raw/master/figs/CBDNet_v13.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Toward Convolutional Blind Denoising of Real Photographs</p>
<p class="pub_author">Shi Guo, Zifei Yan, <b>Kai Zhang</b>, Wangmeng Zuo, Lei Zhang<br>
IEEE International Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2019.<br>
[<a href= "http://openaccess.thecvf.com/content_CVPR_2019/papers/Guo_Toward_Convolutional_Blind_Denoising_of_Real_Photographs_CVPR_2019_paper.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/GuoShi28/CBDNet" target="_blank">Code</a>] 
[<a href="https://scholar.googleusercontent.com/citations?view_op=export_citations&user=0RycFIIAAAAJ&s=0RycFIIAAAAJ:cB__R-XWw9UC&citsig=AMD79ooAAAAAXqB7ElsTWrP4PVj1TdTp7jSa954zkalh&hl=zh-CN&cit_fmt=0" target="_blank">BibTex</a>]
[Citations: <b>80</b>+]</p> </td>
</tr>

<!-- chapter-->
<tr>
<td><img class="proj_thumb" src="https://media.springernature.com/w306/springer-static/cover/book/978-3-319-96029-6.jpg" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Convolutional Neural Networks for Image Denoising and Restoration (Book chapter)</p>
<p class="pub_author">Wangmeng Zuo, <b>Kai Zhang</b>, Lei Zhang<br>
In: M. Bertalmio (eds.), Denoising of Photographic Images and Video: Fundamentals, Open Challenges and New Trends, Springer, 2018.<br>
[<a href= "https://link.springer.com/chapter/10.1007%2F978-3-319-96029-6_4" target="_blank">Paper</a>] 
[<a href="https://scholar.googleusercontent.com/citations?view_op=export_citations&user=0RycFIIAAAAJ&s=0RycFIIAAAAJ:oursBaop5wYC&citsig=AMD79ooAAAAAXqB7MmA3p4lGoD7KQTjiEihhr_TQj4Lg&hl=zh-CN&cit_fmt=0" target="_blank">BibTex</a>]</p> </td>
</tr>



<!-- SPL-->
<tr>
<td><img class="proj_thumb" src="https://www.mathworks.com/matlabcentral/mlc-downloads/downloads/submissions/53349/versions/3/screenshot.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Joint Learning of Multiple Regressors for Single Image Super-Resolution</p>
<p class="pub_author"><b>Kai Zhang</b>, Baoquan Wang, Wangmeng Zuo, Hongzhi Zhang, Lei Zhang.<br>
IEEE Signal Processing Letters (<b>SPL</b>), 23, (1): 102-106, 2016.<br>
[<a href= "https://link.springer.com/chapter/10.1007%2F978-3-319-96029-6_4" target="_blank">Paper</a>] 
[<a href="https://scholar.googleusercontent.com/citations?view_op=export_citations&user=0RycFIIAAAAJ&s=0RycFIIAAAAJ:NtCmTCuxid4C&citsig=AMD79ooAAAAAXqB7ZAN12oA7lZmOrYeQKXROelNoR4AL&hl=zh-CN&cit_fmt=0" target="_blank">BibTex</a>]
[Citations: <b>30</b>+]
</p> </td>
</tr>

<table>

<!-- Services -->
<a id="services" class="anchor"></a>
<h2>Services</h2>
<p>Workshop Organizers: </p>
<font size="2">
<ul>
<li><p>Co-organizer of ECCV 2020 Workshop on Advanced Image Manipulation (AIM). </p></li>
<li><p>Co-organizer of CVPR 2020 Workshop on New Trends in Image Restoration and Enhancement (NTIRE). </p></li>
<li><p>Co-organizer of ICCV 2019 Workshop on Advanced Image Manipulation (AIM). </p></li>
</ul>
</font>


 
<p>Journal Reviewer:  </p>
<font size="2"> 
<ul>
<li>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</li>
<li>International Journal of Computer Vision (IJCV)</li>
<li>IEEE Transactions on Image Processing (TIP)</li>
<li>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</li>
<li>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li>
<li>Computer Vision and Image Understanding (CVIU)</li>
<li>Signal Processing Letters (SPL)</li>
</ul>
</font>


<p>Conference Reviewer: </p>
<font size="2"> 
<ul>
<li>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</li>
<li>International Conference on Computer Vision (ICCV)</li>
<li>European Conference on Computer Vision (ECCV)</li>
<li>AAAI Conference on Artificial Intelligence (AAAI)</li>
<li>International Joint Conferences on Artificial Intelligence (IJCAI)</li>
</ul>
</font>



<!-- awards -->
<a id="awards" class="achor"></a>
<h2>Awards</h2>
<font size="2"> 
<ul>
<li>Outstanding student paper award of HIT, 2018</li>
<li>Fourth place of NTIRE 2018 challenge on single image super-resolution, 2018</li>
<li>National scholarship for doctoral students, 2017</li>
<li>Outstanding student paper award of HIT, 2017</li>
<li>First prize of GUANGXI International Academic Forum, 2017</li>
<li>Best poster award of Valse2017, 2017</li>
</ul>
</font>


<!-- Links -->
<h2>Collaborators</h2>
<ul>
<a href= "http://people.ee.ethz.ch/~timofter/" target="_blank">Radu Timofte</a>, &nbsp
<a href= "https://sites.google.com/site/shuhanggu/" target="_blank">Shuhang Gu</a>, &nbsp
<a href= "https://csdwren.github.io/" target="_blank">Dongwei Ren</a>, &nbsp
<a href= "https://kedema.org/" target="_blank">Kede Ma</a>, &nbsp
<a href= "https://sites.google.com/view/yonghongwei-homepage" target="_blank">Hongwei Yong</a>
</ul>


<div id="footer">
<div id="footer-text">
<!--
All Rights Reserved. Part of page is generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
-->

</div>
</div>
<a href="https://clustrmaps.com/site/1b743"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=7HOnPG-tgP2NBIq9v142wI5iM0mQ3OwnnIRnYxx5SdI&cl=ffffff" width=1pt height=1pt/></a>
</body>
</html>
