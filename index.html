<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="files/jemdoc.css" type="text/css" />

<title>Kai Zhang</title>

</head>
<body>

<!-- Project
<div class="menu"> <a href="#home">Home</a> 
<a href="#publications">Publications</a> 
<a href="#services">Services</a> 
<a href="#awards">Awards</a>  
</div>
 -->
 
<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 
<!--
<div id="toptitle">
<h1>Kai Zhang</h1>
</div>
 -->


<table class="imgtable"><tr><td>
<a href="./"><img src="./files/photo2.jpg" alt="" height="200px" /></a>&nbsp;</td>
<td align="left"><p><font size="4">Kai Zhang (张 凯)</font><br />
<br />
<!--
<a href="https://vision.ee.ethz.ch/the-institute.html">Computer Vision Lab</a><br />
 Department of Information Technology and Electrical Engineering, <a href="https://ethz.ch/en.html" target="_blank">ETH Zurich</a><br />
-->
<br />
School of Intelligence Science and Technology, Nanjing University, Suzhou, China<br />

<br />
Email: cskaizhang@gmail.com <br />
[<a class="p1" href="https://scholar.google.com.hk/citations?user=0RycFIIAAAAJ&hl" target="_blank">Google Scholar</a>] [<a class="p2" href="https://github.com/cszn" target="_blank">Github</a>]
[<a href="https://www.researchgate.net/profile/Kai_Zhang210" target="_blank">ResearchGate</a>]</p>
</td></tr></table>

<h2>Biography</h2>
<p> I am an Associate Professor of the School of Intelligence Science and Technology at Nanjing University, as of March 2024. Previously, I was a postdoctoral researcher at Computer Vision Lab, ETH Zurich, Switzerland, working with 
          Prof. <a href="https://ee.ethz.ch/the-department/faculty/professors/person-detail.OTAyMzM=.TGlzdC80MTEsMTA1ODA0MjU5.html" target="_blank">Luc Van Gool</a>
          and Prof. <a href="http://people.ee.ethz.ch/~timofter/" target="_blank">Radu Timofte</a>.  
          I received my Ph.D. degree from School of Computer Science and Technology, Harbin Institute of Technology, China, in 2019, 
		  under the supervision of Prof. <a href="http://www4.comp.polyu.edu.hk/~cslzhang/" target="_blank">Lei Zhang</a> 
          and Prof. <a href="http://homepage.hit.edu.cn/wangmengzuo" target="_blank">Wangmeng Zuo</a>.
          I was a research assistant from July, 2015 to July, 2017 and from July, 2018 to April, 2019 in Department of Computing of The Hong Kong Polytechnic University.
  </p>


<h2>Research Interest</h2>
I work in the field of image processing, specializing in particular on developing deep learning techniques for inverse problems in low-level computer vision.
I mainly investigate how to incorporate traditional model-based method and deep learning-based method for flexible, effective, efficient and interpretable image restoration. 
Recently, I focus on the following research topics:
<ul>
<li>Deep plug-and-play image restoration</li>
<li>Deep unfolding image restoration</li>
<li>Camera pipeline</li>
<li>Blind image restoration</li>
</ul>


	
<h2>PyTorch Toolbox for Image Restoration</h2>
<ul>
<li> <a href="https://github.com/cszn/KAIR" target="_blank">KAIR</a> (support training and testing for DnCNN, FFDNet, SRMD, USRNet, ESRGAN) </li>
<li> <a href="https://github.com/cszn/DPIR" target="_blank">DPIR</a> (Plug-and-Play Image Restoration with Deep Denoiser Prior)</li>
</ul>


<h2>News</h2>
<ul>
<li>Four papers are accepted in CVPR 2024.
<li>(2022-07) I will serve as a Senior Program Committee (SPC) Member for AAAI 2023.
<li>I am organizing a Special Issue <a href="https://www.mdpi.com/journal/sensors/special_issues/idisrsa_sensors" target="_blank">"Image Denoising and Image Super-Resolution for Sensing Application"</a> on Sensors (IF 3.576), submit your manuscript before 15 December 2022.
<li>We released the testing codes of <a href="https://github.com/cszn/SCUNet" target="_blank">SCUNet</a>.</li>
<li>We released the training codes of <a href="https://github.com/cszn/BSRNet" target="_blank">BSRNet</a> and <a href="https://github.com/cszn/KAIR/blob/master/docs/README_SwinIR.md" target="_blank">SwinIR</a>.</li>
<li><b>All the four submitted papers are accepted by ICCV 2021. Congratulations to Jingyun Liang and Jiaxi Jiang.</b>
<li>One paper is accepted by IEEE TPAMI.</li>
<li>Two papers are accepted in CVPR 2021.</li>
<li>The code of <a href="https://github.com/cszn/BSRNet" target="_blank">BSRNet</a> is available.</li>
<li>The code of <a href="https://github.com/cszn/DPIR" target="_blank">DPIR</a> is available.</li>
<li>The code of <a href="https://github.com/cszn/USRNet" target="_blank">USRNet</a> is available.</li>
<li>I am co-organizing the ECCV 2020 Workshop on <a href="https://data.vision.ee.ethz.ch/cvl/aim20/" target="_blank">Advances in Image Manipulation</a></li>
<li>Two papers are accepted in CVPR 2020.</li>
<li>I am co-organizing the CVPR 2020 Workshop on <a href="https://data.vision.ee.ethz.ch/cvl/ntire20/" target="_blank">New Trends in Image Restoration and Enhancement</a></li>
</ul>

	
<!-- Project -->
<a id="publications" class="anchor"></a>
<h2>Selected Publications</h2>

<table class="imgtable">

<!-- ArXiv 2022-->
<tr>
<td><img class="proj_thumb" src="https://github.com/cszn/SCUNet/raw/main/figs/real_scunet.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Practical Blind Denoising via Swin-Conv-UNet and Data Synthesis</p>
<p class="pub_author"><b>Kai Zhang</b>, Yawei Li, Jingyun Liang, Jiezhang Cao, Yulun Zhang, Tao Tang, Radu Timofte, Luc Van Gool<br>
ArXiv</i>, 2022.<br>
[<a href= "https://github.com/cszn/SCUNet/blob/6e45b78dba1dfecfadc350d52d659d7701fecf17/figs/scunet.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/cszn/SCUNet" target="_blank">PyTorch Testing Code</a>] 
[<a href="https://replicate.com/cszn/scunet" target="_blank">Online demo</a>] 
[<a href="bibtex.html#zhang2022practical" target="_blank">BibTex</a>]
</p> </td>
</tr>

	
<!-- NeurIPS 2022-->
<tr>
<td><img class="proj_thumb" src="https://github.com/JingyunLiang/RVRT/raw/main/assets/teaser_vsr.gif?style=centerme" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Recurrent Video Restoration Transformer with Guided Deformable Attention </p>
<p class="pub_author">Jingyun Liang, Yuchen Fan, Xiaoyu Xiang, Rakesh Ranjan, Eddy Ilg, Simon Green, Jiezhang Cao, <b>Kai Zhang*</b>, Radu Timofte, Luc Van Gool<br>
Thirty-sixth Conference on Neural Information Processing Systems</i> (<b>NeurIPS</b>), 2022.<br>
[<a href= "https://arxiv.org/pdf/2206.02146.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/JingyunLiang/RVRT" target="_blank">PyTorch Code</a>] 
[<a href="bibtex.html#liang2022recurrent" target="_blank">BibTex</a>]
</p> </td>
</tr>	
	
	
<!-- ECCV 2022-->
<tr>
<td><img class="proj_thumb" src="https://github.com/caojiezhang/DAVSR/raw/main/assets/011_ours.gif" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Towards Interpretable Video Super-Resolution via Alternating Optimization </p>
<p class="pub_author">Jiezhang Cao, Jingyun Liang, <b>Kai Zhang*</b>, Wenguan Wang, Qin Wang, Yulun Zhang, Hao Tang, Luc Van Gool<br>
European Conference on Computer Vision</i> (<b>ECCV</b>), 2022.<br>
[<a href= "https://arxiv.org/pdf/2207.10765.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/caojiezhang/DAVSR" target="_blank">PyTorch Code</a>] 
[<a href="bibtex.html#cao2022towards" target="_blank">BibTex</a>]
</p> </td>
</tr>	



<!-- tpami2022-->
<tr>
<td><img class="proj_thumb" src="https://github.com/cszn/DPIR/raw/master/figs/denoiser_arch.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Plug-and-Play Image Restoration with Deep Denoiser Prior </p>
<p class="pub_author"><b>Kai Zhang</b>, Yawei Li, Wangmeng Zuo, Lei Zhang, Luc Van Gool, Radu Timofte<br>
IEEE Transactions on Pattern Analysis and Machine Intelligence</i>(<b>IEEE TPAMI</b>), 2022.<br>
[<a href= "https://arxiv.org/pdf/2008.13751.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/cszn/DPIR" target="_blank">PyTorch Code</a>] 
[<a href="bibtex.html#zhang2020plug" target="_blank">BibTex</a>]
</p> </td>
</tr>


<!-- chapter 2022-->
<tr>
<td><img class="proj_thumb" src="https://github.com/cszn/USRNet/raw/master/figs/category.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Deep plug-and-play and deep unfolding methods for image restoration (Book chapter)</p>
<p class="pub_author"><b>Kai Zhang</b>, Radu Timofte<br>
In: E.R. Davies and Matthew A. Turk (eds.), Advanced Methods and Deep Learning in Computer Vision, Academic Press, 2022.<br>
[<a href= "https://www.sciencedirect.com/science/article/pii/B9780128221099000230#f0020" target="_blank">Paper</a>] 
[<a href="bibtex.html#zhang2022deep" target="_blank">BibTex</a>]</p> </td>
</tr>

	
<!-- ICCVW 2021-->
<tr>
<td><img class="proj_thumb" src="https://github.com/JingyunLiang/SwinIR/raw/main/figs/SwinIR_archi.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">SwinIR: Image Restoration Using Swin Transformer </p>
<p class="pub_author">Jingyun Liang, Jiezhang Cao, Guolei Sun, <b>Kai Zhang*</b>, Luc Van Gool, Radu Timofte<br>
IEEE International Conference on Computer Vision Workshops</i> (<b>ICCVW</b>), 2021.<br>
[<a href= "https://arxiv.org/pdf/2108.10257.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/JingyunLiang/SwinIR" target="_blank">PyTorch Testing Code</a>] 
[<a href="https://github.com/cszn/KAIR" target="_blank">PyTorch Training Code</a>] 
[<a href="bibtex.html#liang2021swinir" target="_blank">BibTex</a>]
</p> </td>
</tr>
	
<!-- ICCV 2021-->
<tr>
<td><img class="proj_thumb" src="https://github.com/cszn/BSRGAN/raw/main/figs/degradationmodel.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Designing a Practical Degradation Model for Deep Blind Image Super-Resolution </p>
<p class="pub_author"><b>Kai Zhang</b>, Jingyun Liang, Luc Van Gool, Radu Timofte<br>
IEEE International Conference on Computer Vision</i> (<b>ICCV</b>), 2021.<br>
[<a href= "https://arxiv.org/pdf/2103.14006.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/cszn/BSRGAN" target="_blank">PyTorch Code</a>] 
[<a href="bibtex.html#zhang2021designing" target="_blank">BibTex</a>]
</p> </td>
</tr>

<!-- ICCV 2021, HCFlow-->
<tr>
<td><img class="proj_thumb" src="https://github.com/JingyunLiang/HCFlow/raw/main/illustrations/architecture.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Hierarchical Conditional Flow: A Unified Framework for Image Super-Resolution and Image Rescaling </p>
<p class="pub_author">Jingyun Liang, Andreas Lugmayr, <b>Kai Zhang*</b>, Martin Danelljan, Luc Van Gool, Radu Timofte<br>
IEEE International Conference on Computer Vision</i> (<b>ICCV</b>), 2021.<br>
[<a href= "https://arxiv.org/pdf/2108.05301.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/JingyunLiang/HCFlow" target="_blank">PyTorch Code</a>] 
[<a href="bibtex.html#liang2021hierarchical" target="_blank">BibTex</a>]
</p> </td>
</tr>
	
<!-- ICCV 2021, MANet-->
<tr>
<td><img class="proj_thumb" src="https://github.com/JingyunLiang/MANet/raw/main/illustrations/MANet.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Mutual Affine Network for Spatially Variant Kernel Estimation in Blind Image Super-Resolution </p>
<p class="pub_author">Jingyun Liang, Guolei Sun, <b>Kai Zhang*</b>, Luc Van Gool, Radu Timofte<br>
IEEE International Conference on Computer Vision</i> (<b>ICCV</b>), 2021.<br>
[<a href= "https://arxiv.org/pdf/2108.05302.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/JingyunLiang/MANet" target="_blank">PyTorch Code</a>] 
[<a href="bibtex.html#liang2021mutual" target="_blank">BibTex</a>]
</p> </td>
</tr>

<!-- ICCV 2021, FBCNN-->
<tr>
<td><img class="proj_thumb" src="https://raw.githubusercontent.com/cszn/KAIR/master/utils/test.bmp" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Towards Flexible Blind JPEG Artifacts Removal </p>
<p class="pub_author">Jiaxi Jiang, <b>Kai Zhang*</b>, Radu Timofte<br>
IEEE International Conference on Computer Vision</i> (<b>ICCV</b>), 2021.<br>
[<a href= "" target="_blank">Paper</a>] 
[<a href="https://github.com/jiaxi-jiang/FBCNN" target="_blank">PyTorch Code</a>] 
[<a href="bibtex.html#jiang2021towards" target="_blank">BibTex</a>]
</p> </td>
</tr>


<!-- CVPR 2021 FKP-->
<tr>
<td><img class="proj_thumb" src="https://github.com/JingyunLiang/FKP/raw/master/data/illustrations/KernelGANFKP.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Flow-based Kernel Prior with Application to Blind Super-Resolution </p>
<p class="pub_author">Jingyun Liang, <b>Kai Zhang*</b>, Shuhang Gu, Luc Van Gool, Radu Timofte<br>
IEEE International Conference on Computer Vision and Pattern Recognition</i> (<b>CVPR</b>), 2021.<br>
[<a href= "https://arxiv.org/pdf/2103.15977.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/JingyunLiang/FKP" target="_blank">PyTorch Code</a>] 
[<a href="bibtex.html#liang2021flow" target="_blank">BibTex</a>]
</p> </td>
</tr>


<!-- AIM2020-->
<tr>
<td><img class="proj_thumb" src="https://data.vision.ee.ethz.ch/cvl/aim20/logos/AIM2020_name_logo.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">AIM 2020 Challenge on Efficient Super-Resolution: Methods and Results </p>
<p class="pub_author"><b>Kai Zhang</b>, Martin Danelljan, Yawei Li, Radu Timofte, others<br>
European Conference on Computer Vision Workshops</i> (<b>ECCVW</b>), 2020.<br>
[<a href= "https://arxiv.org/pdf/2009.06943.pdf" target="_blank">Paper</a>] 
[<a href="bibtex.html#zhang2020aim" target="_blank">BibTex</a>]
</p> </td>
</tr>

<!-- USRNet-->
<tr>
<td><img class="proj_thumb" src="https://github.com/cszn/USRNet/raw/master/figs/architecture.png" alt="" height="50px"/>&nbsp;</td>
<td>
<p class="pub_title">Deep Unfolding Network for Image Super-Resolution </p>
<p class="pub_author"><b>Kai Zhang</b>, Luc Van Gool, Radu Timofte<br>
IEEE International Conference on Computer Vision and Pattern Recognition</i> (<b>CVPR</b>), 2020.<br>
[<a href= "https://arxiv.org/pdf/2003.10428.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/cszn/USRNet" target="_blank">PyTorch Code</a>] 
[<a href="bibtex.html#zhang2020deep" target="_blank">BibTex</a>]
</p> </td>
</tr>

<!-- deblur-->
<tr>
<td><img class="proj_thumb" src="https://github.com/csdwren/SelfDeblur/raw/master/results/demo/lai.jpg" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Neural Blind Deconvolution Using Deep Priors </p>
<p class="pub_author">Dongwei Ren, <b>Kai Zhang</b>, Qilong Wang, Qinghua Hu, Wangmeng Zuo<br>
IEEE International Conference on Computer Vision and Pattern Recognition</i>(<b>CVPR</b>), 2020.<br>
[<a href= "https://arxiv.org/pdf/1908.02197.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/csdwren/SelfDeblur" target="_blank">PyTorch Code</a>] 
[<a href="bibtex.html#ren2019neural" target="_blank">BibTex</a>]
</p> </td>
</tr>

<!-- challenge-->
<tr>
<td><img class="proj_thumb" src="https://data.vision.ee.ethz.ch/cvl/ntire20/logos/NTIRE2020_name_logo.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">NTIRE 2020 Challenge on Perceptual Extreme Super-Resolution: Methods and Results </p>
<p class="pub_author"><b>Kai Zhang</b>, Shuhang Gu, Radu Timofte, and others<br>
IEEE International Conference on Computer Vision and Pattern Recognition Workshops</i>(<b>CVPRW</b>), 2020.<br>
[<a href= "https://arxiv.org/pdf/2005.01056.pdf" target="_blank">Paper</a>] 
[<a href="bibtex.html#zhang2020ntire" target="_blank">BibTex</a>]
</p> </td>
</tr>

<!-- challenge-->
<tr>
<td><img class="proj_thumb" src="https://data.vision.ee.ethz.ch/cvl/aim19/logos/AIM2019_logo.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">AIM 2019 Challenge on Constrained Super-Resolution: Methods and Results</p>
<p class="pub_author"><b>Kai Zhang</b>, Shuhang Gu, Radu Timofte, and others<br>
IEEE International Conference on Computer Vision Workshops (<b>ICCVW</b>), 2019.<br>
[<a href= "https://arxiv.org/pdf/1911.01249.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/cszn/KAIR" target="_blank">PyTorch Code of Winner</a>] 
[<a href="bibtex.html#zhang2019aim" target="_blank">BibTex</a>]
</p> </td>
</tr>

<!-- DPSR-->
<tr>
<td><img class="proj_thumb" src="https://github.com/cszn/DPSR/raw/master/testsets/BSD68/x4_m_dpsrgan/test_14_m_14.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Deep Plug-and-Play Super-Resolution for Arbitrary Blur Kernels</p>
<p class="pub_author"><b>Kai Zhang</b>, Wangmeng Zuo, Lei Zhang<br>
IEEE International Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2019.<br>
[<a href= "http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Deep_Plug-And-Play_Super-Resolution_for_Arbitrary_Blur_Kernels_CVPR_2019_paper.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/cszn/DPSR" target="_blank">PyTorch Code</a>] 
[<a href="bibtex.html#zhang2019deep" target="_blank">BibTex</a>]
</p> </td>
</tr>

<!-- SRMD-->
<tr>
<td><img class="proj_thumb" src="https://github.com/cszn/SRMD/raw/master/figs/architecture.png" alt="" height="55px"/>&nbsp;</td>
<td>
<p class="pub_title">Learning a Single Convolutional Super-Resolution Network for Multiple Degradations</p>
<p class="pub_author"><b>Kai Zhang</b>, Wangmeng Zuo, Lei Zhang<br>
IEEE International Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2018. <br>
[<a href= "http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/1440.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/cszn/SRMD" target="_blank">Matlab Code</a>] 
[<a href="https://github.com/cszn/KAIR" target="_blank">PyTorch Code</a>] 
[<a href="bibtex.html#zhang2018learning" target="_blank">BibTex</a>]
[Citations: <b>670</b>+]</p> </td>
</tr>


<!-- IRCNN-->
<tr>
<td><img class="proj_thumb" src="https://www.mathworks.com/matlabcentral/mlc-downloads/downloads/submissions/62439/versions/6/screenshot.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Learning Deep CNN Denoiser Prior for Image Restoration</p>
<p class="pub_author"><b>Kai Zhang</b>, Wangmeng Zuo, Shuhang Gu, Lei Zhang<br>
IEEE International Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2017. <br>
[<a href= "http://www4.comp.polyu.edu.hk/~cslzhang/paper/IRCNN_CVPR17.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/cszn/IRCNN" target="_blank">Matlab Code</a>] 
[<a href="bibtex.html#zhang2017learning" target="_blank">BibTex</a>]
[Citations: <b>1400</b>+]</p> </td>
</tr>

<!-- FFDNet-->
<tr>
<td><img class="proj_thumb" src="https://github.com/cszn/FFDNet/raw/master/utilities/figs/Frog.gif" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">FFDNet: Toward a Fast and Flexible Solution for CNN-based Image Denoising</p>
<p class="pub_author"><b>Kai Zhang</b>, Wangmeng Zuo, Lei Zhang<br>
IEEE Transactions on Image Processing (<b>TIP</b>), 27(9): 4608-4622, 2018.<br>
[<a href= "http://www4.comp.polyu.edu.hk/~cslzhang/paper/IRCNN_CVPR17.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/cszn/FFDNet" target="_blank">Matlab Code</a>] 
[<a href="https://github.com/cszn/KAIR" target="_blank">PyTorch Code</a>] 
[<a href="bibtex.html#zhang2018ffdnet" target="_blank">BibTex</a>]
[Citations: <b>1300</b>+]</p> </td>
</tr>


<!-- DnCNN-->
<tr>
<td><img class="proj_thumb" src="https://github.com/cszn/DnCNN/raw/master/figs/input.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising</p>
<p class="pub_author"><b>Kai Zhang</b>, Wangmeng Zuo, Yunjin Chen, Deyu Meng, Lei Zhang<br>
IEEE Transactions on Image Processing (<b>TIP</b>), 26(7): 3142-3155, 2017.<br>
[<a href= "https://ieeexplore.ieee.org/document/7839189" target="_blank">Paper</a>] 
[<a href="https://github.com/cszn/DnCNN" target="_blank">Matlab Code</a>] 
[<a href="https://github.com/cszn/KAIR" target="_blank">PyTorch Code</a>] 
[<a href="bibtex.html#zhang2017beyond" target="_blank">BibTex</a>] 
[Citations: <b>4900</b>+] </p> </td>
</tr>

<!-- Blind IQA-->
<tr>
<td><img class="proj_thumb" src="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/83/8167422/8110690/ma4abcdefg-2774045-small.gif" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">End-to-End Blind Image Quality Assessment Using Deep Neural Networks</p>
<p class="pub_author">Kede Ma, Wentao Liu, <b>Kai Zhang</b>, Zhengfang Duanmu, Zhou Wang, Wangmeng Zuo<br>
IEEE Transactions on Image Processing (<b>TIP</b>), 27(3): 1202-1213, 2017.<br>
[<a href= "https://ieeexplore.ieee.org/abstract/document/8110690" target="_blank">Paper</a>] 
[<a href="https://ece.uwaterloo.ca/~zduanmu/tip2018biqa/" target="_blank">Project Page</a>] 
[<a href="bibtex.html#ma2017end" target="_blank">BibTex</a>]
[Citations: <b>300</b>+]</p> </td>
</tr>

<!-- CBDNet-->
<tr>
<td><img class="proj_thumb" src="https://github.com/GuoShi28/CBDNet/raw/master/figs/CBDNet_v13.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Toward Convolutional Blind Denoising of Real Photographs</p>
<p class="pub_author">Shi Guo, Zifei Yan, <b>Kai Zhang</b>, Wangmeng Zuo, Lei Zhang<br>
IEEE International Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2019.<br>
[<a href= "http://openaccess.thecvf.com/content_CVPR_2019/papers/Guo_Toward_Convolutional_Blind_Denoising_of_Real_Photographs_CVPR_2019_paper.pdf" target="_blank">Paper</a>] 
[<a href="https://github.com/GuoShi28/CBDNet" target="_blank">Code</a>] 
[<a href="bibtex.html#guo2019toward" target="_blank">BibTex</a>]
[Citations: <b>550</b>+]</p> </td>
</tr>

<!-- chapter-->
<tr>
<td><img class="proj_thumb" src="https://media.springernature.com/w306/springer-static/cover/book/978-3-319-96029-6.jpg" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Convolutional Neural Networks for Image Denoising and Restoration (Book chapter)</p>
<p class="pub_author">Wangmeng Zuo, <b>Kai Zhang</b>, Lei Zhang<br>
In: M. Bertalmio (eds.), Denoising of Photographic Images and Video: Fundamentals, Open Challenges and New Trends, Springer, 2018.<br>
[<a href= "https://link.springer.com/chapter/10.1007%2F978-3-319-96029-6_4" target="_blank">Paper</a>] 
[<a href="bibtex.html#zuo2018convolutional" target="_blank">BibTex</a>]</p> </td>
</tr>



<!-- SPL-->
<tr>
<td><img class="proj_thumb" src="https://www.mathworks.com/matlabcentral/mlc-downloads/downloads/submissions/53349/versions/3/screenshot.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Joint Learning of Multiple Regressors for Single Image Super-Resolution</p>
<p class="pub_author"><b>Kai Zhang</b>, Baoquan Wang, Wangmeng Zuo, Hongzhi Zhang, Lei Zhang.<br>
IEEE Signal Processing Letters (<b>SPL</b>), 23, (1): 102-106, 2016.<br>
[<a href= "https://link.springer.com/chapter/10.1007%2F978-3-319-96029-6_4" target="_blank">Paper</a>] 
[<a href="bibtex.html#zhang2015joint" target="_blank">BibTex</a>]
[Citations: <b>30</b>+]
</p> </td>
</tr>

<!-- PCM-->
<tr>
<td><img class="proj_thumb" src="https://media.springernature.com/w306/springer-static/cover/book/978-3-319-24075-6.jpg" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Revisiting Single Image Super-Resolution Under Internet Environment: Blur Kernels and Reconstruction Algorithms</p>
<p class="pub_author"><b>Kai Zhang</b>, Xiaoyu Zhou, Hongzhi Zhang, Wangmeng Zuo.<br>
Pacific Rim Conference on Multimedia (<b>PCM</b>), 2015: 677-687<br>
[<a href= "https://link.springer.com/chapter/10.1007/978-3-319-24075-6_65" target="_blank">Paper</a>] 
[<a href="bibtex.html#zhang2015revisiting" target="_blank">BibTex</a>]
</p> </td>
</tr>



<table>

<!-- Services -->
<a id="services" class="anchor"></a>
<h2>Services</h2>
<p>Workshop Organizers: </p>
<font size="2">
<ul>
<li><p>Co-organizer of ECCV 2020 Workshop on Advanced Image Manipulation (AIM). </p></li>
<li><p>Co-organizer of CVPR 2020 Workshop on New Trends in Image Restoration and Enhancement (NTIRE). </p></li>
<li><p>Co-organizer of ICCV 2019 Workshop on Advanced Image Manipulation (AIM). </p></li>
</ul>
</font>


 
<p>Journal Reviewer:  </p>
<font size="2"> 
<ul>
<li>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</li>
<li>International Journal of Computer Vision (IJCV)</li>
<li>IEEE Transactions on Image Processing (TIP)</li>
<li>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</li>
<li>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li>
<li>Computer Vision and Image Understanding (CVIU)</li>
<li>Signal Processing Letters (SPL)</li>
</ul>
</font>


<p>Conference Reviewer: </p>
<font size="2"> 
<ul>
<li>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</li>
<li>International Conference on Computer Vision (ICCV)</li>
<li>European Conference on Computer Vision (ECCV)</li>
<li>AAAI Conference on Artificial Intelligence (AAAI)</li>
<li>International Joint Conferences on Artificial Intelligence (IJCAI)</li>
</ul>
</font>

<!-- students -->
<a id="students" class="achor"></a>
<h2>Students Co-supervised</h2>
<p>PhD students: </p>
<font size="2">
<ul>
<li><p><a href="https://jingyunliang.github.io/" target="_blank">Jingyun Liang</a>, 2019/11 - Present </p></li>
<li><p><a href="https://www.jiezhangcao.com/" target="_blank">Jiezhang Cao</a>, 2020/11 - Present </p></li>
</ul>
</font>	

<p>Master students: </p>
<font size="2"> 
<ul>
<li><a href="https://yuanzhi-zhu.github.io/about/" target="_blank">Yuanzhi Zhu</a>, 2022/07 - Present</li>
<li><a href="https://jiaxi-jiang.com/" target="_blank">Jiaxi Jiang</a>, 2020/09 - 2021/05</li>
</ul>
</font>	


<!-- awards -->
<a id="awards" class="achor"></a>
<h2>Awards</h2>
<font size="2"> 
<ul>
<li>Excellent Doctoral Dissertation of HIT, 2021</li>
<li>First Prize of Natural Science Award of Heilongjiang Province, 2020</li>
<li>Outstanding student paper award of HIT, 2018</li>
<li>Fourth place of NTIRE 2018 challenge on single image super-resolution, 2018</li>
<li>National scholarship for doctoral students, 2017</li>
<li>Outstanding student paper award of HIT, 2017</li>
<li>First prize of GUANGXI International Academic Forum, 2017</li>
<li>Best poster award of Valse2017, 2017</li>
</ul>
</font>


<!-- Links -->
<h2>Collaborators</h2>
<ul>
<a href= "http://people.ee.ethz.ch/~timofter/" target="_blank">Radu Timofte</a>, &nbsp
<a href= "https://sites.google.com/site/shuhanggu/" target="_blank">Shuhang Gu</a>, &nbsp
<a href= "https://csdwren.github.io/" target="_blank">Dongwei Ren</a>, &nbsp
<a href= "https://kedema.org/" target="_blank">Kede Ma</a>, &nbsp
<a href= "https://sites.google.com/view/yonghongwei-homepage" target="_blank">Hongwei Yong</a>
</ul>

<!-- Links 
<h2>Music</h2>
<iframe width="280" height="157" src="https://www.youtube.com/embed/-5qhNRmMilI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>	
<iframe width="280" height="157" src="https://www.youtube.com/embed/AVXejOoPECA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<iframe width="280" height="157" src="https://www.youtube.com/embed/xTRVZbHjmbc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>	
-->
	
	
	
<div id="footer">
<div id="footer-text">
<!--
All Rights Reserved. Part of page is generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
-->

</div>
</div>
<a href="https://clustrmaps.com/site/1b743"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=7HOnPG-tgP2NBIq9v142wI5iM0mQ3OwnnIRnYxx5SdI&cl=ffffff" width=1pt height=1pt/></a>
</body>
</html>
